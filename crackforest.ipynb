{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:27:50.739207Z","iopub.execute_input":"2025-08-10T13:27:50.739543Z","iopub.status.idle":"2025-08-10T13:27:50.749956Z","shell.execute_reply.started":"2025-08-10T13:27:50.739520Z","shell.execute_reply":"2025-08-10T13:27:50.748945Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"file_id =\"1_ouiYlKVS23GiRSu-WEBwOv8pXNc2_VM\"\nfile_name = \"ceramic-cracks-dataset-master.zip\"\ntarget_folder = \"unzipedCeramics\"\n\nif not os.path.exists(file_name):\n    !gdown --id {file_id} -O {file_name}\nelse:\n    print(\"Zip dosyası zaten mevcut,indirilmedi\")\n\nif not os.path.exists(target_folder):\n    print(f\"'{target_folder}' oluşturuluyor ve zip dosyası içine açılıyor...\")\n    !mkdir -p \"{target_folder}\"\n    !unzip -q -n \"{file_name}\" -d \"{target_folder}\"\n    print(\"İşlem tamamlandı.\")\nelse:\n    print(f\"'{target_folder}'zaten mevut zip açılmadı.\")\n##https://drive.google.com/file/d/1_ouiYlKVS23GiRSu-WEBwOv8pXNc2_VM/view?usp=drive_link","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T12:44:31.023095Z","iopub.execute_input":"2025-08-10T12:44:31.024360Z","iopub.status.idle":"2025-08-10T12:44:41.005145Z","shell.execute_reply.started":"2025-08-10T12:44:31.024318Z","shell.execute_reply":"2025-08-10T12:44:41.003930Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1_ouiYlKVS23GiRSu-WEBwOv8pXNc2_VM\nFrom (redirected): https://drive.google.com/uc?id=1_ouiYlKVS23GiRSu-WEBwOv8pXNc2_VM&confirm=t&uuid=96d41c92-7dc4-4763-978d-dc32cd882740\nTo: /kaggle/working/ceramic-cracks-dataset-master.zip\n100%|██████████████████████████████████████| 37.9M/37.9M [00:03<00:00, 9.57MB/s]\n'unzipedCeramics' oluşturuluyor ve zip dosyası içine açılıyor...\nİşlem tamamlandı.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"BASE_PATH = '/kaggle/working/unzipedCeramics/ceramic-cracks-dataset-master/'\nTRAIN_IMAGE_DIR = os.path.join(BASE_PATH, 'train', 'image')\nTRAIN_MASK_DIR = os.path.join(BASE_PATH, 'train', 'label')\nTEST_IMAGE_DIR = os.path.join(BASE_PATH, 'test', 'image')\n\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nBATCH_SIZE = 8\nEPOCHS = 15 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:36:05.490997Z","iopub.execute_input":"2025-08-10T13:36:05.492007Z","iopub.status.idle":"2025-08-10T13:36:05.497259Z","shell.execute_reply.started":"2025-08-10T13:36:05.491962Z","shell.execute_reply":"2025-08-10T13:36:05.495996Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"train_image_paths = sorted([os.path.join(TRAIN_IMAGE_DIR, f) for f in os.listdir(TRAIN_IMAGE_DIR) if f.endswith('.png')])\ntrain_mask_paths = sorted([os.path.join(TRAIN_MASK_DIR, f) for f in os.listdir(TRAIN_MASK_DIR) if f.endswith('.png')])\n\nval_image_paths = sorted([os.path.join(VAL_IMAGE_DIR, f) for f in os.listdir(VAL_IMAGE_DIR) if f.endswith('.png')])\n\n\nprint(f\"Eğitim için bulunan resim/maske çifti: {len(train_image_paths)}\")\nprint(f\"Doğrulama için bulunan resim/maske çifti: {len(val_image_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:21:24.025369Z","iopub.execute_input":"2025-08-10T13:21:24.025683Z","iopub.status.idle":"2025-08-10T13:21:24.034612Z","shell.execute_reply.started":"2025-08-10T13:21:24.025660Z","shell.execute_reply":"2025-08-10T13:21:24.033575Z"}},"outputs":[{"name":"stdout","text":"Eğitim için bulunan resim/maske çifti: 100\nDoğrulama için bulunan resim/maske çifti: 67\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"train_image_paths = sorted([os.path.join(TRAIN_IMAGE_DIR, f) for f in os.listdir(TRAIN_IMAGE_DIR) if f.endswith('.png')])\ntrain_mask_paths = sorted([os.path.join(TRAIN_MASK_DIR, f) for f in os.listdir(TRAIN_MASK_DIR) if f.endswith('.png')])\n\nprint(f\"Eğitim için {len(train_image_paths)} adet resim ve maske bulundu.\")\n\ndef load_data_into_memory(image_paths, mask_paths):\n    images_list = []\n    masks_list = []\n    \n    print(f\"{len(image_paths)} adet görüntü ve maske hafızaya yükleniyor...\")\n    \n    for img_path, mask_path in zip(image_paths, mask_paths):\n        img = Image.open(img_path).convert('RGB')\n        img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n        images_list.append(np.array(img) / 255.0)\n        \n        mask = Image.open(mask_path).convert('L')\n        mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), resample=Image.NEAREST)\n        mask = np.array(mask)\n        mask = np.expand_dims(mask, axis=-1)\n        masks_list.append((mask > 0).astype(np.float32))\n\n    return np.array(images_list), np.array(masks_list)\n\n# Bütün train setini yüklüyoruz\nX_train, y_train = load_data_into_memory(train_image_paths, train_mask_paths)\n\nprint(\"\\nVeri yükleme tamamlandı.\")\nprint(f\"X_train (resimler) şekli: {X_train.shape}\")\nprint(f\"y_train (maskeler) şekli: {y_train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:36:08.232955Z","iopub.execute_input":"2025-08-10T13:36:08.233962Z","iopub.status.idle":"2025-08-10T13:36:08.979275Z","shell.execute_reply.started":"2025-08-10T13:36:08.233929Z","shell.execute_reply":"2025-08-10T13:36:08.978496Z"}},"outputs":[{"name":"stdout","text":"Eğitim için 100 adet resim ve maske bulundu.\n100 adet görüntü ve maske hafızaya yükleniyor...\n\nVeri yükleme tamamlandı.\nX_train (resimler) şekli: (100, 224, 224, 3)\ny_train (maskeler) şekli: (100, 224, 224, 1)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"def build_unet_with_mobilenetv2():\n    base_model = tf.keras.applications.MobileNetV2(input_shape=[IMG_HEIGHT, IMG_WIDTH, 3], include_top=False, weights='imagenet')\n    layer_names = [\n        'block_1_expand_relu', 'block_3_expand_relu', 'block_6_expand_relu', \n        'block_13_expand_relu', 'block_16_project',\n    ]\n    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n    encoder = Model(inputs=base_model.input, outputs=base_model_outputs)\n    encoder.trainable = False\n    inputs = Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])\n    skips = encoder(inputs)\n    x = skips[-1]\n    skips = reversed(skips[:-1])\n    for up, skip in zip([512, 256, 128, 64], skips):\n        x = Conv2DTranspose(up, 2, strides=2, padding='same')(x)\n        x = concatenate([x, skip])\n        x = Conv2D(up, 3, padding='same', activation='relu')(x)\n        x = Conv2D(up, 3, padding='same', activation='relu')(x)\n    x = Conv2DTranspose(32, 2, strides=2, padding='same')(x)\n    output = Conv2D(1, 1, activation='sigmoid')(x)\n    return Model(inputs=inputs, outputs=output)\n\nmodel = build_unet_with_mobilenetv2()\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:36:25.328600Z","iopub.execute_input":"2025-08-10T13:36:25.328957Z","iopub.status.idle":"2025-08-10T13:36:26.273091Z","shell.execute_reply.started":"2025-08-10T13:36:25.328931Z","shell.execute_reply":"2025-08-10T13:36:26.272231Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"print(\"\\nModel eğitimi başlıyor (Doğrulama seti olmadan)...\")\nhistory = model.fit(\n    X_train, y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:36:37.077778Z","iopub.execute_input":"2025-08-10T13:36:37.078153Z","iopub.status.idle":"2025-08-10T13:46:31.017009Z","shell.execute_reply.started":"2025-08-10T13:36:37.078098Z","shell.execute_reply":"2025-08-10T13:46:31.016142Z"}},"outputs":[{"name":"stdout","text":"\nModel eğitimi başlıyor (Doğrulama seti olmadan)...\nEpoch 1/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.8572 - loss: 0.3336\nEpoch 2/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9631 - loss: 0.1472\nEpoch 3/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9504 - loss: 0.1474\nEpoch 4/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9590 - loss: 0.1270\nEpoch 5/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9524 - loss: 0.1228\nEpoch 6/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9557 - loss: 0.1173\nEpoch 7/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9602 - loss: 0.0974\nEpoch 8/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9549 - loss: 0.1059\nEpoch 9/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9599 - loss: 0.0976\nEpoch 10/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9613 - loss: 0.0950\nEpoch 11/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9598 - loss: 0.0973\nEpoch 12/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9646 - loss: 0.0847\nEpoch 13/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9665 - loss: 0.0824\nEpoch 14/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9646 - loss: 0.0835\nEpoch 15/15\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9637 - loss: 0.0882\n","output_type":"stream"}],"execution_count":49}]}